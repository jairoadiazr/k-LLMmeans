{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ef2618-2761-4722-8215-db6c6eff7635",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YOUR_OPENAI_KEY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkLLMmeans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kLLMmeans, get_embeddings, summarize_cluster\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexperiment_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, cluster_metrics, avg_closest_distance\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n",
      "File \u001b[1;32m~\\York University\\SC-jairo-research - Documents\\llm_centroid\\k-LLMmeans\\kLLMmeans.py:13\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# OpenAI API Key (set your own key here)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[1;32m---> 13\u001b[0m             api_key \u001b[38;5;241m=\u001b[39m YOUR_OPENAI_KEY\n\u001b[0;32m     14\u001b[0m         )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings\u001b[39m(texts, model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-small\u001b[39m\u001b[38;5;124m\"\u001b[39m, emb_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m'\u001b[39m, instructor_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    Get embeddings using OpenAI's text-embedding-3-small.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'YOUR_OPENAI_KEY' is not defined"
     ]
    }
   ],
   "source": [
    "from kLLMmeans import kLLMmeans, get_embeddings, summarize_cluster\n",
    "from experiment_utils import load_dataset, cluster_metrics, avg_closest_distance\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "import numpy as np\n",
    "import json, pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d82f2a4-d421-4cf1-8610-90710937b03a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m oracle_summary_embeddings \u001b[38;5;241m=\u001b[39m oracle_centroids\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m---> 36\u001b[0m     results_dict[emb_type][seed] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m#kmeans\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mnum_clusters, max_iter\u001b[38;5;241m=\u001b[39mmax_iter, random_state\u001b[38;5;241m=\u001b[39mseed)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "max_iter = 120\n",
    "\n",
    "data_list = ['clinic','bank77','massive_I','massive_D','goemo']\n",
    "\n",
    "for data in data_list:\n",
    "    results_dict = {}\n",
    "    \n",
    "    with open(\"processed_data/data_\" + data + \".pkl\", \"rb\") as f:\n",
    "        data_dict = pickle.load(f)\n",
    "        \n",
    "    labels = data_dict['labels']\n",
    "    num_clusters = data_dict['num_clusters']   \n",
    "    documents = data_dict['documents']\n",
    "    text_features = data_dict['embeddings']\n",
    "    #oracle_summaries = data_dict['summaries']\n",
    "    prompt = data_dict['prompt']\n",
    "    text_type = data_dict['text_type']\n",
    "    \n",
    "    \n",
    "    oracle_cluster_assignments = labels\n",
    "    \n",
    "    for emb_type in ['distilbert', 'openai', 'e5-large', 'sbert']:\n",
    "        \n",
    "        results_dict[emb_type] = \"\"\n",
    "        emb_data = text_features[emb_type]\n",
    "        \n",
    "        #calculate oracle embeddings\n",
    "        oracle_clustered_embeddings = {i: [] for i in range(num_clusters)}\n",
    "        for embedding, cluster in zip(emb_data, oracle_cluster_assignments):\n",
    "            oracle_clustered_embeddings[cluster].append(embedding)\n",
    "        oracle_centroids = [np.mean(oracle_clustered_embeddings[i], axis=0) if oracle_clustered_embeddings[i] else None for i in range(num_clusters)]\n",
    "        #oracle_summary_embeddings = get_embeddings(oracle_summaries, emb_type = emb_type)\n",
    "        oracle_summary_embeddings = oracle_centroids\n",
    "        \n",
    "        for seed in range(10):\n",
    "            results_dict[emb_type][seed] = {}\n",
    "    \n",
    "            #kmeans\n",
    "            kmeans = KMeans(n_clusters=num_clusters, max_iter=max_iter, random_state=seed)\n",
    "            kmeans_assignments = kmeans.fit_predict(text_features[emb_type])\n",
    "            kmeans_centroids = kmeans.cluster_centers_\n",
    "            results = cluster_metrics(np.array(labels), kmeans_assignments, oracle_centroids, kmeans_centroids, oracle_summary_embeddings)\n",
    "            data_results ={'assignments':kmeans_assignments,\n",
    "                           'final_centroids':kmeans_centroids,\n",
    "                           'results':results}\n",
    "            \n",
    "            results_dict[emb_type][seed]['kmeans'] = data_results\n",
    "            \n",
    "            print([data, emb_type, seed, 'kmeans', results])\n",
    "    \n",
    "            #kmedoids\n",
    "            kmedoids = KMedoids(n_clusters=num_clusters, max_iter = max_iter, random_state=seed)\n",
    "            kmedoids.fit(text_features[emb_type])\n",
    "            kmedoids_assignments = kmedoids.labels_\n",
    "            kmedoids_indices = kmedoids.medoid_indices_\n",
    "            kmedoids_centroids = text_features[emb_type][kmedoids_indices]\n",
    "            results = cluster_metrics(np.array(labels), kmedoids_assignments, oracle_centroids, kmedoids_centroids, oracle_summary_embeddings)\n",
    "            data_results ={'assignments':kmedoids_assignments,\n",
    "                           'final_centroids':kmedoids_centroids,\n",
    "                           'results':results}\n",
    "            \n",
    "            results_dict[emb_type][seed]['kmedoids'] = data_results\n",
    "            \n",
    "            print([data, emb_type, seed, 'kmedoids', results])\n",
    "            \n",
    "            for force_context_length in [0, 10]:\n",
    "                results_dict[emb_type][seed][force_context_length] = {}\n",
    "                            \n",
    "                for max_llm_iter in [1, 5]:\n",
    "                    \n",
    "                    assignments, final_summaries, final_summary_embeddings, final_centroids, summaries_evolution, centroids_evolution = kLLMmeans(documents,\n",
    "                                                             prompt = prompt, text_type = text_type,\n",
    "                                                             num_clusters = num_clusters, \n",
    "                                                             force_context_length = force_context_length, max_llm_iter = max_llm_iter, \n",
    "                                                             max_iter = max_iter, tol=1e-4, random_state = seed, \n",
    "                                                             emb_type = emb_type,\n",
    "                                                             text_features = text_features[emb_type])\n",
    "                    \n",
    "                    results = cluster_metrics(np.array(labels), assignments,\n",
    "                                              oracle_centroids, final_centroids, \n",
    "                                              oracle_summary_embeddings, final_summary_embeddings)\n",
    "    \n",
    "                    data_results ={'assignments':assignments,\n",
    "                                   'final_summaries':final_summaries,\n",
    "                                   'final_summary_embeddings':final_summary_embeddings,\n",
    "                                   'final_centroids':final_centroids,\n",
    "                                   'summaries_evolution':summaries_evolution,\n",
    "                                   'centroids_evolution':centroids_evolution,\n",
    "                                   'results':results}\n",
    "                    \n",
    "                    results_dict[emb_type][seed][force_context_length][max_llm_iter] = data_results\n",
    "                    \n",
    "                    print([data, emb_type, seed, force_context_length, max_llm_iter, results])\n",
    "                    sddf\n",
    "                    # Save as pkl file\n",
    "                    with open(\"results/sims_offline_results_\" + emb_type + '_' + data + \".pkl\", \"wb\") as f:\n",
    "                        pickle.dump(results_dict, f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5912d5c8-c2b1-45da-b19e-8963c76a327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3128ff8b-2713-4337-a917-1262785a112b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
