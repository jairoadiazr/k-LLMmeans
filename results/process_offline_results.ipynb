{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f828282-87b8-49a7-85f8-46a492d6cec9",
   "metadata": {},
   "source": [
    "# Read simulated results and save all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b48b6b-df2d-4f33-bfbf-71d452f9907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for data in ['bank77', 'clinic', 'goemo' , 'massive_I', 'massive_D']:\n",
    "    results_dict = {}\n",
    "    for emb_type in ['distilbert', 'sbert', 'openai', 'e5-large']:\n",
    "        \n",
    "        results_dict[emb_type] = {}\n",
    "        \n",
    "        # Open the pickle file\n",
    "        with open(\"sims_offline_results_\" + emb_type + \"_\" + data + \".pkl\", \"rb\") as file:\n",
    "            cur_results = pickle.load(file)\n",
    "\n",
    "        for seed in range(10):\n",
    "            for method in ['kmeans','kmeadoids','spectral','agglomerative','gmm']:\n",
    "                results_dict[emb_type][seed][method] = cur_results[emb_type][seed][method]\n",
    "\n",
    "            for llm_type in ['gpt-4o','gpt-3.5-turbo','llama3.3-70b','deepseek-chat','claude-3-7-sonnet-20250219']:\n",
    "\n",
    "                try:\n",
    "                    results_dict[emb_type][seed][llm_type] = {}\n",
    "\n",
    "                    for force_context_length in [0, 10]:\n",
    "                        results_dict[emb_type][seed][llm_type][force_context_length] = {} \n",
    "                        \n",
    "                        for max_llm_iter in [1, 5]:\n",
    "                            results_dict[emb_type][seed][llm_type][max_llm_iter] = cur_results[emb_type][seed][method][force_context_length][max_llm_iter]\n",
    "                \n",
    "        with open(\"results_all_\" + data + \".pkl\", \"wb\") as f:\n",
    "            pickle.dump(results_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e0710-dc78-4912-9262-979fa14445cd",
   "metadata": {},
   "source": [
    "## Process all simulated results and calculate average and std for ACC, NMI, DIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c95a59-7633-459d-bd73-c9b8f0c7ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "results_summary = {}\n",
    "\n",
    "for data in ['bank77', 'clinic', 'goemo' , 'massive_I', 'massive_D']:\n",
    "    results_summary[data] = {}\n",
    "    \n",
    "    with open(\"results_all_\" + data + \".pkl\", \"rb\") as file:\n",
    "        results_dict = pickle.load(file)\n",
    "\n",
    "    \n",
    "    for emb_type in ['distilbert', 'openai','e5-large', 'sbert']:\n",
    "        results_summary[data][emb_type] = {}\n",
    "        \n",
    "        for method in ['k-means','k-medoids','Spectral','GMM','Agglomerative']:\n",
    "            results_summary[data][emb_type][method] = {}\n",
    "            acc = []\n",
    "            nmi = []\n",
    "            cen = []\n",
    "            for seed in range(10):\n",
    "                cur_results = results_dict[emb_type][seed][method]['results']\n",
    "                acc.append(cur_results[0])\n",
    "                nmi.append(cur_results[1])\n",
    "                cen.append(cur_results[2])\n",
    "\n",
    "            results_summary[data][emb_type][method]['average'] = list(np.round([100*np.mean(acc), 100*np.mean(nmi)],3)) + [np.round(np.mean(cen),3)]\n",
    "            results_summary[data][emb_type][method]['std'] = list(np.round([100*np.std(acc), 100*np.std(nmi)],3)) + [np.round(np.std(cen),3)]\n",
    "\n",
    "        for llm_type in ['gpt-3.5-turbo','gpt-4o','llama3.3-70b','deepseek-chat','claude-3-7-sonnet-20250219']:        results_summary[data][emb_type][llm_type] = {}\n",
    "            for force in [0, 10]:\n",
    "                for niter in [1,5]:\n",
    "                    results_summary[data][emb_type][llm_type][str(force) + '-' + str(niter)] = {}\n",
    "                    acc = []\n",
    "                    nmi = []\n",
    "                    cen = []\n",
    "                    for seed in range(10):\n",
    "                        cur_results = results_dict[emb_type][seed][llm_type][force][niter]['results']\n",
    "                        acc.append(cur_results[0])\n",
    "                        nmi.append(cur_results[1])\n",
    "                        cen.append(cur_results[2])\n",
    "                    results_summary[data][emb_type][llm_type][str(force) + '-' + str(niter)]['average'] = list(np.round([100*np.mean(acc), 100*np.mean(nmi)],1)) + [np.round(np.mean(cen),3)]\n",
    "                    results_summary[data][emb_type][llm_type][str(force) + '-' + str(niter)]['std'] = list(np.round([100*np.std(acc), 100*np.std(nmi)],3)) + [np.round(np.std(cen),3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67396c-1166-4194-b378-073818d2a9e8",
   "metadata": {},
   "source": [
    "# Table including all traditional + all kllmeans with gpt-4o + all embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac1e65f-4eda-4eb7-b0eb-2c984527457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = {}\n",
    "emb_type = 'openai'\n",
    "llm_type = 'gpt-4o'\n",
    "\n",
    "for data in ['bank77','clinic', 'goemo', 'massive_D','massive_I']:\n",
    "    line[data] = {}\n",
    "    for emb_type in ['distilbert', 'openai','e5-large', 'sbert']:\n",
    "        \n",
    "        line[data][emb_type] = {}\n",
    "        acc = {'average':[], 'std':[]}\n",
    "        nmi = {'average':[], 'std':[]}\n",
    "        cen = {'average':[], 'std':[]}\n",
    "        method_names = []\n",
    "        for method in ['0-1','0-5','10-1','10-5']:\n",
    "            cur_results = results_summary[data][emb_type][llm_type][method]\n",
    "            acc['average'].append(cur_results['average'][0])\n",
    "            nmi['average'].append(cur_results['average'][1])\n",
    "            cen['average'].append(cur_results['average'][2])\n",
    "            acc['std'].append(cur_results['std'][0])\n",
    "            nmi['std'].append(cur_results['std'][1])\n",
    "            cen['std'].append(cur_results['std'][2])\n",
    "            \n",
    "            if method == '10-1':\n",
    "                cur_method = '\\\\quad \\\\emph{FS-single}'\n",
    "            elif method == '10-5':\n",
    "                cur_method = '\\\\quad \\\\emph{FS-multiple}'\n",
    "            elif method == '0-1':\n",
    "                cur_method = '\\\\quad \\\\emph{single}'\n",
    "            elif method == '0-5':\n",
    "                cur_method = '\\\\quad \\\\emph{multiple}'\n",
    "    \n",
    "            method_names.append(cur_method)\n",
    "       \n",
    "        for other_method in ['kmeans','kmedoids','gmm','agglomerative','spectral']:\n",
    "            cur_results = results_summary[data][emb_type][other_method]\n",
    "    \n",
    "            acc['average'].append(cur_results['average'][0])\n",
    "            nmi['average'].append(cur_results['average'][1])\n",
    "    \n",
    "            cen['average'].append(cur_results['average'][2])\n",
    "            acc['std'].append(cur_results['std'][0])\n",
    "            nmi['std'].append(cur_results['std'][1])\n",
    "            cen['std'].append(cur_results['std'][2])\n",
    "    \n",
    "            method_names.append(other_method)\n",
    "    \n",
    "        # Find the maximum value\n",
    "        #val = max(acc['average'])\n",
    "        #acc['average'] = [f\"{{\\\\bf {x}}}\" if x == val else x for x in acc['average']]\n",
    "    \n",
    "        #val = max(nmi['average'])\n",
    "        #nmi['average'] = [f\"{{\\\\bf {x}}}\" if x == val else x for x in nmi['average']]\n",
    "    \n",
    "        #val = min(cen['average'])\n",
    "        #cen['average'] = [f\"{{\\\\bf {x}}}\" if x == val else x for x in cen['average']]\n",
    "        \n",
    "        for ii in range(len(method_names)):\n",
    "            cur_method = method_names[ii]\n",
    "            line[data][emb_type][cur_method] = cur_method + '&' + str(acc['average'][ii]) + '(' + str(acc['std'][ii]) + ')&' + str(nmi['average'][ii]) + '(' + str(nmi['std'][ii]) + ')&' + str(cen['average'][ii]) + '(' + str(cen['std'][ii]) + ')'\n",
    "\n",
    "for data in ['bank77','clinic', 'goemo', 'massive_D','massive_I']:\n",
    "    print(\"-\"*10)\n",
    "    print(data)\n",
    "    print(\"\")\n",
    "    text = \"\"\n",
    "    for emb_type in ['distilbert', 'openai','e5-large', 'sbert']:\n",
    "        text = text + '\\\\hline\\n\\\\\\\\\\n\\\\emph{' + emb_type + \"}&&&\\\\\\\\\\n\"\n",
    "        text = text + '\\\\hline\\n'\n",
    "        text = text + \"k-LLMmeans&&&\\\\\\\\\\n\"\n",
    "        for ii in range(len(method_names)):\n",
    "            cur_method = method_names[ii]\n",
    "            text = text + line[data][emb_type][cur_method] + '\\\\\\\\\\n'\n",
    "    print(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d0c88-37c6-4736-82e4-73b4d6fe7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "line[data][emb_type][cur_method]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a22417d-e714-44ba-83e7-d360f537935a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
